#!/bin/bash

# Define cleanup function
cleanup() {
    echo ""
    echo "ğŸ›‘ Stopping MLX Server..."
    if [ -n "$MLX_PID" ]; then
        kill $MLX_PID
    fi
    echo "ğŸ›‘ Stopping Docker Containers..."
    docker-compose down
    exit
}

# Trap SIGINT (Ctrl+C)
trap cleanup SIGINT

echo "ğŸš€ Starting SoftSkill v2 Stack..."

# 0. Auto-Download Model if Missing
MODEL_DIR="ai_engine/models/softskill-llama3.2-3b"
REPO_ID="KingDor/softskill-llama3.2-3b"

if [ ! -f "$MODEL_DIR/config.json" ]; then
    echo "ğŸ“¥ Model not found locally. Downloading from Hugging Face ($REPO_ID)..."
    mkdir -p "$MODEL_DIR"
    # Use huggingface-cli to download
    huggingface-cli download $REPO_ID --local-dir $MODEL_DIR --local-dir-use-symlinks False
    echo "âœ… Download Complete."
else
    echo "âœ… Model found locally."
fi

# 1. Start MLX Server (Host)
echo "ğŸ§  Booting AI Brain (MLX on M2)..."
python3 ai_engine/run_mlx_server.py --model ai_engine/models/softskill-llama3.2-3b --port 8081 --host 0.0.0.0 > mlx_server.log 2>&1 &
MLX_PID=$!

# Wait for MLX to be ready
echo "â³ Waiting for Brain to load..."
sleep 5
# Optional: Check if port 8081 is listening
while ! lsof -i :8081 > /dev/null; do
    sleep 1
done
echo "âœ… Brain is Online (PID: $MLX_PID)"

# 2. Start Docker Stack (Backend now runs in TypeScript via Dockerfile)
echo "ğŸ³ Starting Backend & Frontend..."
docker-compose up --build

# Wait for docker to exit
wait
